{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from datetime import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib.dates import DateFormatter\n",
    "from matplotlib.patches import Polygon\n",
    "from matplotlib.collections import PatchCollection\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_with_background(ax, alpha = .5):\n",
    "\t\"\"\"\n",
    "\tCreates a plot with a background image.\n",
    "\n",
    "\tParameters:\n",
    "\t- ax: The matplotlib axis object containing the plot.\n",
    "\t\"\"\"\n",
    "\t# Path to your image file\n",
    "\timage_path = '../data-raw/background/image3195.png'\n",
    "\t\n",
    "\t# Coordinates for the image placement\n",
    "\timage_extent = (0, 51, -0.02, 14.214)\n",
    "\n",
    "\t# Load the background image\n",
    "\timg = mpimg.imread(image_path)\n",
    "\t\n",
    "\t# If an extent is provided, use it to correctly scale and position the image\n",
    "\tif image_extent:\n",
    "\t\tax.imshow(img, aspect='auto', extent=image_extent, zorder=-1, alpha = alpha)\n",
    "\telse:\n",
    "\t\tax.imshow(img, aspect='auto', zorder=-1, alpha = alpha)\n",
    "\t\n",
    "\treturn ax\n",
    "\n",
    "\n",
    "\n",
    "# Load the JSON data\n",
    "with open('../data-raw/background/config.json') as f:\n",
    "\tdata = json.load(f)\n",
    "\n",
    "# Navigate to the singlesensors within bern-multi01\n",
    "geometries = data['multisensors']['bern-multi01']['geometries']\n",
    "\n",
    "# Filter geometries for zones containing \"entry\" in their name\n",
    "geometries = [g for g in geometries if g['type'] == 'ZONE' and 'entry' in g['name'].lower()]\n",
    "\n",
    "# Preprocess geometries to remove \"act_\" prefix from names\n",
    "for geometry in geometries:\n",
    "\tif geometry['name'].startswith('act_entry_'):\n",
    "\t\tgeometry['name'] = geometry['name'][10:]  # Remove the first 4 characters 'act_'\n",
    "\n",
    "# Add additional seating areas\n",
    "seating_area_coords = [[11.31, 2.6], [47.5, 2.6], [47.5, 6.5], [11.31, 6.5]]\n",
    "seating_area_geometry = {\n",
    "\t'geometry': seating_area_coords,\n",
    "\t'type': 'ZONE',\n",
    "\t'name': 'seating area 1'\n",
    "}\n",
    "geometries.append(seating_area_geometry)\n",
    "\n",
    "seating_area_2_coords = [[13.5, 0], [47.5, 0], [47.5, 1.75], [13.5, 1.75]]\n",
    "seating_area_2_geometry = {\n",
    "\t'geometry': seating_area_2_coords,\n",
    "\t'type': 'ZONE',\n",
    "\t'name': 'seating area 2'\n",
    "}\n",
    "geometries.append(seating_area_2_geometry)\n",
    "\n",
    "seating_area_3_coords = [[8-1.8-0.7, 8.8], [8-1.8, 8.8], [8-1.8, 8.8+4], [8-1.8-0.7, 8.8+4]]\n",
    "seating_area_3_geometry = {\n",
    "\t'geometry': seating_area_3_coords,\n",
    "\t'type': 'ZONE',\n",
    "\t'name': 'seating area 3'\n",
    "}\n",
    "geometries.append(seating_area_3_geometry)\n",
    "\n",
    "seating_area_4_coords = [[8.2-2.4, 6.3], [8.2, 6.3], [8.2, 6.3+.5], [8.2-2.4, 6.3+.5]]\n",
    "seating_area_4_geometry = {\n",
    "\t'geometry': seating_area_4_coords,\n",
    "\t'type': 'ZONE',\n",
    "\t'name': 'seating area 4'\n",
    "}\n",
    "geometries.append(seating_area_4_geometry)\n",
    "\n",
    "# Add presumptive TB area\n",
    "check_area = [[8, .8], [11.3, .8], [11.3, 6.2], [8, 6.2]]\n",
    "check_area = {\n",
    "\t'geometry': check_area,\n",
    "\t'type': 'ZONE',\n",
    "\t'name': 'Check area'\n",
    "}\n",
    "geometries.append(check_area)\n",
    "check_tb_area = [[9.1, 2.6], [11.3, 2.6], [11.3, 3.7], [9.1, 3.7]]\n",
    "check_tb_area = {\n",
    "\t'geometry': check_tb_area,\n",
    "\t'type': 'ZONE',\n",
    "\t'name': 'TB area'\n",
    "}\n",
    "geometries.append(check_tb_area)\n",
    "\n",
    "\n",
    "\n",
    "def plot_with_background_geom(ax, geometries):\n",
    "\t\"\"\"\n",
    "\tPlots the geometries on a background image.\n",
    "\n",
    "\tParameters:\n",
    "\t- ax: The matplotlib axes object where the plot will be drawn.\n",
    "\t- geometries: A list of geometry dictionaries, each containing 'geometry', 'type', and 'name' keys.\n",
    "\n",
    "\tReturns:\n",
    "\t- The modified axes object with the geometries plotted.\n",
    "\t\"\"\"\n",
    "\t# Plot the background image first\n",
    "\tax = plot_with_background(ax, 1)\n",
    "\n",
    "\t# Color cycle for different polygons\n",
    "\tcolors = plt.cm.viridis(np.linspace(0, 1, len(geometries)))\n",
    "\n",
    "\tfor i, geometry in enumerate(geometries):\n",
    "\t\t# Extract the coordinates directly from the 'geometry' key\n",
    "\t\tcoords = geometry['geometry']\n",
    "\t\t\n",
    "\t\t# Check if the geometry is a LINE or a ZONE to decide on closure\n",
    "\t\tif geometry['type'] == 'ZONE':\n",
    "\t\t\tclosed = True\n",
    "\t\telse:  # For 'LINE', do not close the polygon\n",
    "\t\t\tclosed = False\n",
    "\t\t\n",
    "\t\t# Create a polygon or line from the coordinates\n",
    "\t\tpolygon = Polygon(xy=coords, closed=closed, color=colors[i], label=geometry['name'], alpha=0.5)\n",
    "\t\t\n",
    "\t\t# Add the polygon or line to the plot\n",
    "\t\tax.add_patch(polygon)\n",
    "\t\t\n",
    "\t\t# Label the polygon or line with its name\n",
    "\t\t# Use the first vertex for the label position\n",
    "\t\tax.annotate(geometry['name'], xy=coords[0], color='white', weight='bold')\n",
    "\n",
    "\t# Adjust the legend to be below the plot\n",
    "\tax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05), shadow=True, ncol=2)\n",
    "\n",
    "\treturn ax\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 12))\n",
    "ax = plot_with_background(ax, 1)\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 12))\n",
    "ax = plot_with_background_geom(ax, geometries)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unlinked tracks\n",
    "test_unlinked = pd.read_csv('../data-clean/tracking/unlinked/2024-06-26.csv')\n",
    "test_unlinked['timestamp'] = pd.to_datetime(test_unlinked['time'], unit='ms', origin='unix', utc=True)\n",
    "n_unlink = test_unlinked['track_id'].nunique()\n",
    "\n",
    "# linked tracks\n",
    "mapping = pd.read_csv('../data-clean/tracking/linked/2024-06-26.csv')\n",
    "test_linked = test_unlinked.merge(mapping, left_on='track_id', right_on='raw_track_id', how='left')\n",
    "test_linked['track_id'] = test_linked['track_id_y'].combine_first(test_linked['track_id_x'])\n",
    "test_linked = test_linked.drop(columns=['track_id_x', 'track_id_y'])\n",
    "n_link = test_linked['track_id'].nunique()\n",
    "\n",
    "# linked tracks\n",
    "print(f'Number of unlinked tracks: {n_unlink}')\n",
    "print(f'Number of linked tracks: {n_link}')\n",
    "prop_links = (n_unlink - n_link) / n_unlink * 100\n",
    "print(f'Proportion of tracks linked: {prop_links:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute proportion of complete and lost tracks\n",
    "def categorize_track(group):\n",
    "\t\t\"\"\"Categorizes each track based on 'near_entry' status.\"\"\"\n",
    "\t\tfirst = group.iloc[0]['in_tb_cs']\n",
    "\t\tlast = group.iloc[-1]['in_tb_cs']\n",
    "\t\tif first or last:\n",
    "\t\t\treturn \"TB area staff\"\n",
    "\t\tfirst = group.iloc[0]['near_entry']\n",
    "\t\tlast = group.iloc[-1]['near_entry']\n",
    "\t\tif not first and last:\n",
    "\t\t\treturn \"Lost start\"\n",
    "\t\telif first and not last:\n",
    "\t\t\treturn \"Lost end\"\n",
    "\t\telif not first and not last:\n",
    "\t\t\treturn \"Lost both\"\n",
    "\t\telse:\n",
    "\t\t\treturn \"Complete\"\n",
    "\t\t\n",
    "def count_category_tracks(df):\n",
    "\t\t\"\"\"Processes each dataset to compute track proportions.\"\"\"\n",
    "\t\tcategories = df.groupby('track_id', group_keys=False).apply(categorize_track, include_groups=False).reset_index(name='Category')\n",
    "\t\tcategory_counts = categories['Category'].value_counts().reset_index()\n",
    "\t\tcategory_counts.columns = ['Label', 'Number of Tracks']\n",
    "\t\ttotal_tracks = len(categories)\n",
    "\t\tcategory_counts['Proportion'] = (category_counts['Number of Tracks'] / total_tracks) * 100\n",
    "\t\treturn category_counts.set_index('Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_csv = [f for f in os.listdir(\"../data-clean/tracking/unlinked/\") if f.endswith('.csv')]\n",
    "\n",
    "results_df = pd.DataFrame(columns=[\n",
    "  'date', \n",
    "  'no_tracks_raw', 'no_tracks_matched', 'prop_links', \n",
    "  'mean_no_links', 'max_no_links',\n",
    "  'complete_raw', 'complete_matched'\n",
    "  ]).astype ({\n",
    "    'date': 'str',\n",
    "    'no_tracks_raw': 'int',\n",
    "    'no_tracks_matched': 'int',\n",
    "    'prop_links': 'float64',\n",
    "    'mean_no_links': 'float64',\n",
    "    'max_no_links': 'int',\n",
    "    'complete_raw': 'float64',\n",
    "    'complete_matched': 'float64'\n",
    "})\n",
    "\n",
    "for f in date_csv:\n",
    "  # load data\n",
    "  print(f)\n",
    "  date = f.replace('.csv', '')\n",
    "  unlinked_data = pd.read_csv(os.path.join(\"../data-clean/tracking/unlinked/\", f))\n",
    "  mapping_data = pd.read_csv(os.path.join(\"../data-clean/tracking/linked/\", f))\n",
    "  linked_data = unlinked_data.merge(mapping_data, left_on='track_id', right_on='raw_track_id', how='left')\n",
    "  linked_data['track_id'] = linked_data['track_id_y'].combine_first(linked_data['track_id_x'])\n",
    "  linked_data = linked_data.drop(columns=['track_id_x', 'track_id_y'])\n",
    "  \n",
    "  # number of links\n",
    "  n_ul = unlinked_data['track_id'].nunique()\n",
    "  n_l = linked_data['track_id'].nunique()\n",
    "  p_l = (n_ul - n_l) / n_ul\n",
    "  \n",
    "  # mean and max number of links per track_id\n",
    "  n_link_per_track = linked_data.groupby('track_id', as_index=False)['raw_track_id'].nunique().rename(columns={'raw_track_id': 'links'})\n",
    "  mean_n_l = np.mean(n_link_per_track['links'])\n",
    "  max_n_l = np.max(n_link_per_track['links'])\n",
    "  \n",
    "  # data quality\n",
    "  unlinked_qual = count_category_tracks(unlinked_data)\n",
    "  linked_qual = count_category_tracks(linked_data)\n",
    "  \n",
    "  # Append new data to the DataFrame\n",
    "  new_row = pd.DataFrame({\n",
    "      'date': [date],\n",
    "      'no_tracks_raw': [n_ul],\n",
    "      'no_tracks_matched': [n_l],\n",
    "      'prop_links': [p_l],\n",
    "      'mean_no_links': [mean_n_l],\n",
    "      'max_no_links': [max_n_l],\n",
    "      'complete_raw': [unlinked_qual['Proportion']['Complete']/100],\n",
    "      'complete_matched': [linked_qual['Proportion']['Complete']/100]\n",
    "  })\n",
    "  results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "\n",
    "results_df.sort_values(by='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming results_df is already defined and contains the specified columns\n",
    "\n",
    "# Create a figure with 3 subplots arranged in a single row\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Plot boxplot for 'no_links_matched'\n",
    "sns.boxplot(ax=axes[0], data=results_df, y='no_tracks_matched')\n",
    "axes[0].set_title('No. track IDs')\n",
    "\n",
    "# Plot boxplot for 'prop_links'\n",
    "sns.boxplot(ax=axes[1], data=results_df, y='prop_links')\n",
    "axes[1].set_title('Prop. of links made')\n",
    "\n",
    "# Plot boxplot for 'complete_matched'\n",
    "sns.boxplot(ax=axes[2], data=results_df, y='complete_matched')\n",
    "axes[2].set_title('Prop. of complete tracks')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance between unlinked tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duration distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_track_duration(df):\n",
    "\t\"\"\"\n",
    "\tComputes the duration of each track.\n",
    "\t\n",
    "\tParameters:\n",
    "\t- df: A pandas DataFrame with 'track_id' and 'time' columns.\n",
    "\t\n",
    "\tReturns:\n",
    "\t- A pandas DataFrame with 'track_id' and 'duration' for each track.\n",
    "\t\"\"\"\n",
    "\t# Calculate the duration by subtracting the first time from the last time for each track\n",
    "\tduration_df = df.groupby('track_id')['time'].apply(lambda x: x.max() - x.min()).reset_index(name='duration')\n",
    "\t\n",
    "\t# Convert duration to a more readable format if needed, e.g., total seconds\n",
    "\tduration_df['duration'] = duration_df['duration'] / 1000 / 60  # Convert milliseconds to minutes\n",
    "\t\n",
    "\treturn duration_df\n",
    "\n",
    "def plot_track_duration_histogram(duration_list):\n",
    "\t\"\"\"\n",
    "\tPlots histograms of the duration of each track for multiple datasets.\n",
    "\t\n",
    "\tParameters:\n",
    "\t- duration_list: A list of pandas DataFrames with 'track_id' and 'duration' columns.\n",
    "\t\n",
    "\tReturns:\n",
    "\t- axs: A list of matplotlib axis objects containing the histograms.\n",
    "\t\"\"\"\n",
    "\t# Determine the grid size\n",
    "\tn = len(duration_list)\n",
    "\tnrows = int(n**0.5) + (1 if n % int(n**0.5) > 0 else 0)  # Add an extra row if there are more items than a perfect square\n",
    "\tncols = n if nrows == 1 else int(n / nrows) + (n % nrows > 0)\n",
    "\t\n",
    "\t# Create a figure and axes for the grid of histograms\n",
    "\tfig, axs = plt.subplots(nrows, ncols, figsize=(5*ncols, 4*nrows), squeeze=False)\n",
    "\t\n",
    "\t# Flatten the axs array for easy iteration if there's more than one row or column\n",
    "\taxs = axs.flatten()\n",
    "\t\n",
    "\t# Plot each histogram\n",
    "\tfor i, duration_df in enumerate(duration_list):\n",
    "\t\taxs[i].hist(duration_df['duration'], bins=20, color='skyblue', edgecolor='black', log=True)\n",
    "\t\taxs[i].set_title(f'Histogram of Track Durations {i+1}')\n",
    "\t\taxs[i].set_xlabel('Duration (minutes)')\n",
    "\t\taxs[i].set_ylabel('Frequency')\n",
    "\t\n",
    "\t# Hide any unused subplots\n",
    "\tfor j in range(i + 1, len(axs)):\n",
    "\t\tfig.delaxes(axs[j])\n",
    "\t\n",
    "\t# Adjust layout to prevent overlap\n",
    "\tplt.tight_layout()\n",
    "\t\n",
    "\t# Return the list of axis objects for further manipulation or saving\n",
    "\treturn axs\n",
    "\n",
    "test_linked_duration = compute_track_duration(test_linked)\n",
    "test_unlinked_duration = compute_track_duration(test_unlinked)\n",
    "ax = plot_track_duration_histogram([test_unlinked_duration, test_linked_duration])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_track_distance(df):\n",
    "\t\"\"\"\n",
    "\tComputes the total distance of each track using Euclidean distance in a more efficient manner.\n",
    "\t\n",
    "\tParameters:\n",
    "\t- df: A pandas DataFrame with 'track_id', 'position_x', and 'position_y' columns.\n",
    "\t\n",
    "\tReturns:\n",
    "\t- A pandas DataFrame with 'track_id' and 'total_distance' for each track.\n",
    "\t\"\"\"\n",
    "\t# Calculate shifted positions for x and y\n",
    "\tdf['shifted_x'] = df.groupby('track_id')['position_x'].shift(-1)\n",
    "\tdf['shifted_y'] = df.groupby('track_id')['position_y'].shift(-1)\n",
    "\t\n",
    "\t# Vectorized calculation of the Euclidean distance between consecutive points within each track\n",
    "\tdf['distance'] = np.sqrt((df['shifted_x'] - df['position_x'])**2 + (df['shifted_y'] - df['position_y'])**2)\n",
    "\t\n",
    "\t# Drop the last row of each track where the shift results in NaN values\n",
    "\tdf.dropna(subset=['shifted_x', 'shifted_y'], inplace=True)\n",
    "\t\n",
    "\t# Sum the distances for each track to get the total distance\n",
    "\ttotal_distance_df = df.groupby('track_id')['distance'].sum().reset_index(name='total_distance')\n",
    "\t\n",
    "\treturn total_distance_df\n",
    "\n",
    "def plot_track_distance_histogram(distance_list):\n",
    "\t\"\"\"\n",
    "\tPlots histograms of the total distance of each track for multiple datasets, using Euclidean distance.\n",
    "\t\n",
    "\tParameters:\n",
    "\t- distance_list: A list of pandas DataFrames with 'track_id' and 'total_distance' columns.\n",
    "\t\n",
    "\tReturns:\n",
    "\t- axs: A list of matplotlib axis objects containing the histograms.\n",
    "\t\"\"\"\n",
    "\t# Determine the grid size\n",
    "\tn = len(distance_list)\n",
    "\tnrows = int(n**0.5) + (1 if n % int(n**0.5) > 0 else 0)  # Add an extra row if there are more items than a perfect square\n",
    "\tncols = n if nrows == 1 else int(n / nrows) + (n % nrows > 0)\n",
    "\t\n",
    "\t# Create a figure and axes for the grid of histograms\n",
    "\tfig, axs = plt.subplots(nrows, ncols, figsize=(5*ncols, 4*nrows), squeeze=False)\n",
    "\t\n",
    "\t# Flatten the axs array for easy iteration if there's more than one row or column\n",
    "\taxs = axs.flatten()\n",
    "\t\n",
    "\t# Plot each histogram\n",
    "\tfor i, distance_df in enumerate(distance_list):\n",
    "\t\taxs[i].hist(distance_df['total_distance'], bins=20, color='skyblue', edgecolor='black', log=True)\n",
    "\t\taxs[i].set_title(f'Histogram of Track Total Distances {i+1} (Euclidean)')\n",
    "\t\taxs[i].set_xlabel('Total Distance (m)')\n",
    "\t\taxs[i].set_ylabel('Frequency')\n",
    "\t\n",
    "\t# Hide any unused subplots\n",
    "\tfor j in range(i + 1, len(axs)):\n",
    "\t\tfig.delaxes(axs[j])\n",
    "\t\n",
    "\t# Adjust layout to prevent overlap\n",
    "\tplt.tight_layout()\n",
    "\t\n",
    "\t# Return the list of axis objects for further manipulation or saving\n",
    "\treturn axs\n",
    "\n",
    "test_linked_distance = compute_track_distance(test_linked)\n",
    "test_unlinked_distance = compute_track_distance(test_unlinked)\n",
    "ax = plot_track_distance_histogram([test_unlinked_distance, test_linked_distance])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of made links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute number of made links\n",
    "test_links = test_linked.groupby('track_id')['raw_track_id'].nunique().reset_index(name='links')\n",
    "\n",
    "# Determine the range of the data\n",
    "min_links = int(test_links['links'].min())\n",
    "max_links = int(test_links['links'].max())\n",
    "\n",
    "# Create integer bins\n",
    "bins = np.arange(min_links, max_links + 2)\n",
    "\n",
    "# Plotting the histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "test_links['links'].hist(bins=bins, alpha=0.75, log=True)\n",
    "plt.title('Histogram of Links per Track ID')\n",
    "plt.xlabel('Number of Links per Track ID')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Track IDs over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tracks_time(df_list):\n",
    "\t\"\"\"\n",
    "\tCounts the number of unique track IDs per second, averages these counts per minute for multiple datasets, and plots this on line graphs.\n",
    "\t\n",
    "\tParameters:\n",
    "\t- df_list: A list of pandas DataFrames with columns 'time' (as datetime), 'track_id', 'position_x', and 'position_y'.\n",
    "\t\"\"\"\n",
    "\t# Determine the grid size\n",
    "\tn = len(df_list)\n",
    "\tnrows = int(n**0.5) + (1 if n % int(n**0.5) > 0 else 0)\n",
    "\tncols = n if nrows == 1 else int(n / nrows) + (n % nrows > 0)\n",
    "\t\n",
    "\t# Create a figure for the grid of line graphs\n",
    "\tfig, axs = plt.subplots(nrows, ncols, figsize=(5*ncols, 4*nrows), squeeze=False)\n",
    "\t\n",
    "\t# Flatten the axs array for easy iteration if there's more than one row or column\n",
    "\taxs = axs.flatten()\n",
    "\t\n",
    "\t# Find the maximum average count of unique track IDs per minute across all DataFrames\n",
    "\tmax_count = 0\n",
    "\tfor df in df_list:\n",
    "\t\tdf_copy = df.copy()\n",
    "\t\tdf_copy['time'] = df_copy['time']\n",
    "\t\tdf_copy['time'] = pd.to_datetime(df_copy['time'], unit='ms', origin='unix', utc=True)\n",
    "\t\tdf_copy.set_index('time', inplace=True)\n",
    "\t\ttrack_counts_per_second = df_copy['track_id'].resample('S').nunique()\n",
    "\t\ttrack_counts_per_minute = track_counts_per_second.resample('T').mean()\n",
    "\t\tmax_count = max(max_count, track_counts_per_minute.max())\n",
    "\t\n",
    "\tfor i, df in enumerate(df_list):\n",
    "\t\t# Work on a copy of the DataFrame to avoid modifying the original\n",
    "\t\tdf_copy = df.copy()\n",
    "\t\t\n",
    "\t\t# Ensure 'time' is in datetime format\n",
    "\t\tdf_copy['time'] = df_copy['time']\n",
    "\t\tdf_copy['time'] = pd.to_datetime(df_copy['time'], unit='ms', origin='unix', utc=True)\n",
    "\t\t\n",
    "\t\t# Set 'time' as the index\n",
    "\t\tdf_copy.set_index('time', inplace=True)\n",
    "\t\t\n",
    "\t\t# Resample to 1-second intervals, counting unique track IDs in each interval\n",
    "\t\ttrack_counts_per_second = df_copy['track_id'].resample('S').nunique()\n",
    "\t\t\n",
    "\t\t# Resample to 1-minute intervals, averaging the counts per second\n",
    "\t\ttrack_counts_per_minute = track_counts_per_second.resample('T').mean()\n",
    "\t\t\n",
    "\t\t# Plotting\n",
    "\t\taxs[i].plot(track_counts_per_minute.index, track_counts_per_minute, color='blue')\n",
    "\t\taxs[i].set_title(f'Average Number of Track IDs per Minute {i+1}')\n",
    "\t\taxs[i].set_xlabel('Time')\n",
    "\t\taxs[i].set_ylabel('Average Number of Track IDs')\n",
    "\t\taxs[i].grid(True)\n",
    "\t\taxs[i].xaxis.set_major_formatter(DateFormatter('%H:%M'))\n",
    "\t\t\n",
    "\t\t# Set uniform y-axis limits\n",
    "\t\taxs[i].set_ylim(0, max_count)\n",
    "\t\n",
    "\t# Hide any unused subplots\n",
    "\tfor j in range(i + 1, len(axs)):\n",
    "\t\tfig.delaxes(axs[j])\n",
    "\t\n",
    "\t# Adjust layout to prevent overlap\n",
    "\tplt.tight_layout()\n",
    "\t\n",
    "\tplt.show()\n",
    "\n",
    "plot_tracks_time([test_unlinked, test_linked])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of tracks per unit space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tracks_spatial(df, square_length=0.5):\n",
    "\t\"\"\"\n",
    "\tCounts the number of unique tracks per unit space and plots a heatmap over a background image set by the plot_with_background function.\n",
    "\t\n",
    "\tParameters:\n",
    "\t- df: A pandas DataFrame with columns 'track_id', 'position_x', and 'position_y'.\n",
    "\t- square_length: The length of the side of each square unit (in meters).\n",
    "\t\"\"\"\n",
    "\t# Define the extent of the space\n",
    "\tx_min, x_max, y_min, y_max = 0, 51, -0.02, 14.214\n",
    "\t\n",
    "\t# Calculate the number of bins along each axis\n",
    "\tx_bins = int(np.ceil((x_max - x_min) / square_length))\n",
    "\ty_bins = int(np.ceil((y_max - y_min) / square_length))\n",
    "\t\n",
    "\t# Create a 2D histogram of track counts per unit space\n",
    "\theatmap, _, _ = np.histogram2d(df['position_x'], df['position_y'], bins=[x_bins, y_bins], range=[[x_min, x_max], [y_min, y_max]])\n",
    "\t\n",
    "\t# Mask the 0 values\n",
    "\tmasked_heatmap = np.ma.masked_where(heatmap == 0, heatmap)\n",
    "\n",
    "\t# Create a plot\n",
    "\tfig, ax = plt.subplots(figsize=(10,8))\n",
    "\t\n",
    "\t# Call plot_with_background to set the background image\n",
    "\tplot_with_background(ax, 1)\n",
    "\t\n",
    "\t# Overlay the heatmap\n",
    "\tim = ax.imshow(masked_heatmap.T, extent=[x_min, x_max, y_min, y_max], origin='lower', cmap='hot', alpha=0.5)\n",
    "\n",
    "\t# Manually specify the position and size of the colorbar\n",
    "\tcbar_ax = fig.add_axes([0.15, 0.2, 0.7, 0.02])  # Adjust these values as needed\n",
    "\t\n",
    "\t# Add a colorbar to the heatmap\n",
    "\tfig.colorbar(im, cax=cbar_ax, ax=ax, label='Number of Tracks', orientation='horizontal')\n",
    "\t\n",
    "\tax.set_xlabel('Position X (m)')\n",
    "\tax.set_ylabel('Position Y (m)')\n",
    "\tax.set_title('Heatmap of Tracks per Unit Space')\n",
    "\t\n",
    "\tplt.show()\n",
    "\n",
    "\n",
    "plot_tracks_spatial(test_linked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial distribution of tracking starts and ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a plot with the background image\n",
    "def plot_first_last_tracks(df):\n",
    "\t\"\"\"\n",
    "\tPlots the first and last track of each track_id in a scatter plot.\n",
    "\t\n",
    "\tParameters:\n",
    "\t- df: A pandas DataFrame with at least 'track_id', 'position_x', and 'position_y' columns.\n",
    "\t\n",
    "\tReturns:\n",
    "\t- ax: A matplotlib axis object containing the scatter plot.\n",
    "\t\"\"\"\n",
    "\t# Ensure the DataFrame is sorted by track_id and then by the tracking time or equivalent\n",
    "\tdf_sorted = df.sort_values(by=['track_id', 'time'])\n",
    "\t\n",
    "\t# Group by track_id and get the first and last entry for each track_id\n",
    "\tfirst_tracks = df_sorted.groupby('track_id').first().reset_index()\n",
    "\tlast_tracks = df_sorted.groupby('track_id').last().reset_index()\n",
    "\t\n",
    "\t# Create a scatter plot\n",
    "\tfig, ax = plt.subplots(figsize=(16, 12))\n",
    "\t\n",
    "\t# Plot the first track points in green\n",
    "\tax.scatter(first_tracks['position_x'], first_tracks['position_y'], color='green', label='First Track', s = 1)\n",
    "\t\n",
    "\t# Plot the last track points in red\n",
    "\tax.scatter(last_tracks['position_x'], last_tracks['position_y'], color='red', label='Last Track', s = 1)\n",
    "\t\n",
    "\t# Adding legend to distinguish first and last tracks\n",
    "\tax.legend()\n",
    "\t\n",
    "\t# Labeling the axes\n",
    "\tax.set_xlabel('Position X')\n",
    "\tax.set_ylabel('Position Y')\n",
    "\tax.set_title('First and Last Tracks of Each Track ID')\n",
    "\t\n",
    "\t# Return the axis object for further manipulation or saving\n",
    "\treturn ax\n",
    "\n",
    "\n",
    "ax = plot_first_last_tracks(test_unlinked)\n",
    "ax = plot_with_background_geom(ax, geometries)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_first_last_tracks(test_linked)\n",
    "ax = plot_with_background_geom(ax, geometries)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_track_proportions(dfs: list) -> pd.DataFrame:\n",
    "\t\"\"\"\n",
    "\tComputes the track proportions for given datasets, categorizing each track based on its 'near_entry' status at the start and end.\n",
    "\t\n",
    "\tParameters:\n",
    "\t- dfs: A list of pandas DataFrames, where the first DataFrame is the unlinked dataset and the second (optional) is the linked dataset.\n",
    "\t\n",
    "\tReturns:\n",
    "\t- A pandas DataFrame with the number of tracks per category for each dataset and the difference between them.\n",
    "\t\"\"\"\t\n",
    "\t# Process the first dataset (unlinked)\n",
    "\tunlinked_counts = process_dataset(dfs[0])\n",
    "\t\n",
    "\tresults = unlinked_counts.copy()\n",
    "\tresults.columns = ['Number of Tracks (Unlinked)', 'Proportion (%) (Unlinked)']\n",
    "\t\n",
    "\t# If a second dataset (linked) is provided, process it and compute differences\n",
    "\tif len(dfs) > 1:\n",
    "\t\tlinked_counts = process_dataset(dfs[1])\n",
    "\t\tlinked_counts.columns = ['Number of Tracks (Linked)', 'Proportion (%) (Linked)']\n",
    "\t\t\n",
    "\t\t# Merge the results\n",
    "\t\tresults = results.join(linked_counts, how='outer').fillna(0)\n",
    "\t\t\n",
    "\t\t# Compute differences\n",
    "\t\tresults['Difference in Number'] = results['Number of Tracks (Linked)'] - results['Number of Tracks (Unlinked)']\n",
    "\t\tresults['Difference in Proportion (%)'] = results['Proportion (%) (Linked)'] - results['Proportion (%) (Unlinked)']\n",
    "\t\t\n",
    "\t\t# Format the columns to show numbers and proportions in a single column\n",
    "\t\tresults['Unlinked'] = results['Number of Tracks (Unlinked)'].round(0).astype(int).astype(str) + \" (\" + results['Proportion (%) (Unlinked)'].round(0).astype(int).astype(str) + \"%)\"\n",
    "\t\tresults['Linked'] = results['Number of Tracks (Linked)'].round(0).astype(int).astype(str) + \" (\" + results['Proportion (%) (Linked)'].round(0).astype(int).astype(str) + \"%)\"\n",
    "\t\tresults['Difference'] = results['Difference in Number'].round(0).astype(int).astype(str) + \" (\" + results['Difference in Proportion (%)'].round(0).astype(int).astype(str) + \"%)\"\n",
    "\t\t\n",
    "\t\t# Select and rename the final columns\n",
    "\t\tfinal_columns = ['Unlinked', 'Linked', 'Difference']\n",
    "\telse:\n",
    "\t\t# Format the column for a single dataset\n",
    "\t\tresults['Unlinked'] = results['Number of Tracks (Unlinked)'].round(0).astype(int).astype(str) + \" (\" + results['Proportion (%) (Unlinked)'].round(0).astype(int).astype(str) + \"%)\"\n",
    "\t\tfinal_columns = ['Unlinked']\n",
    "\t\n",
    "\treturn results[final_columns].reset_index()\n",
    "\n",
    "result = compute_track_proportions([test_unlinked, test_linked])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lost_tracks(df):\n",
    "    # Categorize tracks\n",
    "    category = df.groupby('track_id').apply(categorize_track).reset_index(name='Category')\n",
    "    # Filter lost tracks\n",
    "    lost_tracks = pd.merge(df[['track_id', 'time']], category, on='track_id')\n",
    "    lost_tracks = lost_tracks[lost_tracks['Category'].isin(['Lost start', 'Lost end', 'Lost both'])]\n",
    "    lost_times_start = lost_tracks.drop_duplicates(subset='track_id', keep='first')\n",
    "    lost_times_start = lost_times_start[lost_times_start['Category'].isin(['Lost start', 'Lost both'])]\n",
    "    lost_times_end = lost_tracks.drop_duplicates(subset='track_id', keep='last') \n",
    "    lost_times_end = lost_times_end[lost_times_end['Category'].isin(['Lost end', 'Lost both'])]\n",
    "    lost_times = pd.concat([lost_times_start, lost_times_end], axis=0)\n",
    "    \n",
    "    # Create a DataFrame for lost times\n",
    "    # print(pd.to_datetime(lost_times, unit='ms', origin='unix', utc=True).max())\n",
    "    lost_times['time'] = lost_times['time']\n",
    "    lost_times['time'] = pd.to_datetime(lost_times['time'], unit='ms', origin='unix', utc=True)\n",
    "    \n",
    "    # Set time as index and resample to count lost tracks every minute\n",
    "    lost_times.set_index('time', inplace=True)\n",
    "    lost_counts = lost_times.resample('T').size()\n",
    "    \n",
    "    # Plot the counts\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    lost_counts.plot()\n",
    "    plt.title('Number of lost tracks over time')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Number of lost tracks')\n",
    "    plt.show()\n",
    "\n",
    "plot_lost_tracks(test_unlinked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bad tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dxy(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\t\"\"\"\n",
    "\tComputes the Euclidean distance between consecutive points within each track_id\n",
    "\tand adds it as a new column 'dxy' to the DataFrame.\n",
    "\t\n",
    "\tParameters:\n",
    "\t- df (pd.DataFrame): The input DataFrame with columns 'time', 'track_id', 'position_x', and 'position_y'.\n",
    "\t\n",
    "\tReturns:\n",
    "\t- pd.DataFrame: The DataFrame with an additional column 'dxy'.\n",
    "\t\"\"\"\n",
    "\t# Group by 'track_id' and calculate the differences within each group\n",
    "\tdf['delta_x'] = df.groupby('track_id')['position_x'].diff()\n",
    "\tdf['delta_y'] = df.groupby('track_id')['position_y'].diff()\n",
    "\t\n",
    "\t# Compute the Euclidean distance (dxy) using the differences\n",
    "\tdf['dxy'] = np.sqrt(df['delta_x']**2 + df['delta_y']**2)\n",
    "\t\n",
    "\treturn df\n",
    "\n",
    "test_unlinked = compute_dxy(test_unlinked)\n",
    "\n",
    "def plot_bad_tracks(df, min_dxy=4):\n",
    "\t# Filter track_ids with any dxy greater than min_dxy\n",
    "\ttrack_ids = df[df['dxy'] > min_dxy]['track_id'].unique()\n",
    "\t\n",
    "\t# Randomly sample up to 5 of these track_ids\n",
    "\tsampled_track_ids = np.random.choice(track_ids, size=min(5, len(track_ids)), replace=False)\n",
    "\t\n",
    "\t# Setup plot with background\n",
    "\tfig, ax = plt.subplots(figsize=(10, 6))\n",
    "\tax = plot_with_background(ax, 1)\n",
    "\t\n",
    "\t# Color cycle for different tracks\n",
    "\tcolor_cycle = plt.cm.tab10(np.linspace(0, 1, 10))\n",
    "\t\n",
    "\t# Plot each track\n",
    "\tfor idx, track_id in enumerate(sampled_track_ids):\n",
    "\t\ttrack_data = df[df['track_id'] == track_id].reset_index(drop=True)\n",
    "\t\tcolor = color_cycle[idx % len(color_cycle)]\n",
    "\t\t\n",
    "\t\t# Iterate through segments of the track\n",
    "\t\tfor i in range(1, len(track_data)):\n",
    "\t\t\tsegment = track_data.iloc[i-1:i+1]\n",
    "\t\t\tif segment['dxy'].iloc[-1] > min_dxy:\n",
    "\t\t\t\t# Dashed line for segments where dxy > min_dxy\n",
    "\t\t\t\tline_style = '--'\n",
    "\t\t\telse:\n",
    "\t\t\t\t# Solid line otherwise\n",
    "\t\t\t\tline_style = '-'\n",
    "\t\t\tax.plot(segment['position_x'], segment['position_y'], line_style, color=color)\n",
    "\t\t\n",
    "\t\t# Mark the first and last points specifically\n",
    "\t\tax.plot(track_data.iloc[0]['position_x'], track_data.iloc[0]['position_y'], 'o', color=color, markerfacecolor='none')  # Open circle\n",
    "\t\tax.plot(track_data.iloc[-1]['position_x'], track_data.iloc[-1]['position_y'], 'x', color=color)  # Cross\n",
    "\t\n",
    "\tplt.show()\n",
    "\n",
    "plot_bad_tracks(test_unlinked)\n",
    "\n",
    "def count_bad_tracks(df, thresholds=[3, 5, 7, 10]):\n",
    "\t\"\"\"\n",
    "\tCounts the number of bad tracks for different dxy thresholds and returns a table with counts and percentages.\n",
    "\t\n",
    "\tParameters:\n",
    "\t- df (pd.DataFrame): The input DataFrame with columns 'track_id' and 'dxy'.\n",
    "\t- thresholds (list): A list of thresholds to classify bad tracks.\n",
    "\t\n",
    "\tReturns:\n",
    "\t- pd.DataFrame: A DataFrame with columns 'Threshold', 'Count', and 'Percent' of bad tracks.\n",
    "\t\"\"\"\n",
    "\ttotal_tracks = df['track_id'].nunique()\n",
    "\tresults = []\n",
    "\n",
    "\tfor threshold in thresholds:\n",
    "\t\t# Count track_ids with any dxy greater than the current threshold\n",
    "\t\tcount = df[df['dxy'] > threshold]['track_id'].nunique()\n",
    "\t\tpercent = (count / total_tracks) * 100\n",
    "\t\tresults.append({'Threshold': threshold, 'Count': count, 'Percent': percent})\n",
    "\n",
    "\tresults_df = pd.DataFrame(results)\n",
    "\treturn results_df\n",
    "\n",
    "# Example usage\n",
    "bad_tracks_unlinked = count_bad_tracks(test_unlinked)\n",
    "print(bad_tracks_unlinked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample_tracks(df, duration_df, distance_df, link_df, min_time=None, min_distance=None, min_links=1, grid_size=(1, 1), area=None):\n",
    "    \"\"\"\n",
    "    Plots sample tracks with additional information.\n",
    "    \n",
    "    Args:\n",
    "    - df (pd.DataFrame): The main dataframe containing track data.\n",
    "    - duration_df (pd.DataFrame): A dataframe containing the duration of each track.\n",
    "    - distance_df (pd.DataFrame): A dataframe containing the total distance of each track.\n",
    "    - link_df (pd.DataFrame): A dataframe containing the number of links (raw_track_id count) per track_id.\n",
    "    - min_time (Optional[int]): The minimum duration a track must have to be included. Defaults to None.\n",
    "    - min_distance (Optional[float]): The minimum distance a track must cover to be included. Defaults to None.\n",
    "    - min_links (int): The minimum number of raw_track_id that have been linked to form a track_id. Defaults to 1.\n",
    "    - grid_size (tuple): The grid size for plotting multiple tracks. Defaults to (1, 1).\n",
    "    - area (character): The column name of the area that should be targeted for samples.\n",
    "    \"\"\"\n",
    "    \n",
    "    track_info = pd.merge(duration_df, distance_df, on='track_id')\n",
    "    track_info = pd.merge(track_info, link_df, on='track_id')\n",
    "    \n",
    "    if area is not None:\n",
    "        last_raw_track_ids = df.groupby(['track_id','raw_track_id']).tail(1)\n",
    "        last_raw_track_ids = last_raw_track_ids.groupby('track_id').apply(lambda x: x.iloc[:-1] if len(x) > 1 else x)\n",
    "        last_raw_track_ids = last_raw_track_ids.reset_index(drop=True)\n",
    "        track_ids_in_area = last_raw_track_ids.groupby('track_id').filter(lambda x: x[area].any())\n",
    "        track_ids_in_area = track_ids_in_area['track_id'].unique()\n",
    "        area_df = pd.DataFrame(track_ids_in_area, columns=['track_id'])\n",
    "        area_df['in_area'] = True\n",
    "        track_info = pd.merge(track_info, area_df, how='left')\n",
    "        track_info['in_area'] = track_info['in_area'].fillna(False)\n",
    "        track_info = track_info[track_info['in_area']]\n",
    "        \n",
    "    \n",
    "    if min_time is not None:\n",
    "        track_info = track_info[track_info['duration'] >= min_time]\n",
    "    if min_distance is not None:\n",
    "        track_info = track_info[track_info['total_distance'] >= min_distance]\n",
    "    if min_links > 1:\n",
    "        track_info = track_info[track_info['links'] >= min_links]\n",
    "    \n",
    "    if track_info.empty:\n",
    "        print(\"No tracks meet the filtering criteria.\")\n",
    "        return\n",
    "    \n",
    "    num_plots = grid_size[0] * grid_size[1]\n",
    "    sampled_track_ids = track_info.sample(n=num_plots)['track_id'].tolist()\n",
    "    \n",
    "    fig, axs = plt.subplots(grid_size[0], grid_size[1], figsize=(10 * grid_size[1], 6 * grid_size[0]))\n",
    "    axs = axs.flatten()  # Flatten in case of a single row/column to simplify iteration\n",
    "    \n",
    "    for ax, track_id in zip(axs, sampled_track_ids):\n",
    "        track_df = df[df['track_id'] == track_id]\n",
    "        \n",
    "        if track_df.empty:\n",
    "            print(f\"No data for track_id {track_id}.\")\n",
    "            continue\n",
    "        \n",
    "        raw_track_ids = track_df['raw_track_id'].unique()\n",
    "        colors = plt.cm.jet(np.linspace(0, 1, len(raw_track_ids)))\n",
    "        \n",
    "        previous_end_time = None\n",
    "        previous_end_position = None\n",
    "        \n",
    "        for i, raw_track_id in enumerate(raw_track_ids):\n",
    "            segment_df = track_df[track_df['raw_track_id'] == raw_track_id]\n",
    "            \n",
    "            ax.plot(segment_df['position_x'], segment_df['position_y'], '-', color=colors[i], linewidth=1)\n",
    "            \n",
    "            if len(segment_df) >= 1:\n",
    "                ax.plot(segment_df.iloc[0]['position_x'], segment_df.iloc[0]['position_y'], 'o', color=colors[i], markerfacecolor='none', markersize=10)\n",
    "            \n",
    "            if len(segment_df) > 1:\n",
    "                ax.plot(segment_df.iloc[-1]['position_x'], segment_df.iloc[-1]['position_y'], 'x', color=colors[i], markersize=10)\n",
    "            \n",
    "            if len(segment_df) > 2:\n",
    "                ax.plot(segment_df.iloc[1:-1]['position_x'], segment_df.iloc[1:-1]['position_y'], 'o', color=colors[i], markersize=1)\n",
    "            \n",
    "            # Calculate time and distance to previous segment\n",
    "            if previous_end_time is not None and previous_end_position is not None:\n",
    "                time_diff = (segment_df.iloc[0]['timestamp'] - previous_end_time).total_seconds()\n",
    "                distance_diff = np.sqrt((segment_df.iloc[0]['position_x'] - previous_end_position[0])**2 + \n",
    "                                        (segment_df.iloc[0]['position_y'] - previous_end_position[1])**2)\n",
    "                label_text = f\"{i + 1}: {raw_track_id} ({time_diff:.2f}s, {distance_diff:.2f}m)\"\n",
    "            else:\n",
    "                label_text = f\"{i + 1}: {raw_track_id}\"\n",
    "            \n",
    "            ax.text(1.05, 1 - (i * 0.05), label_text, transform=ax.transAxes, verticalalignment='top', horizontalalignment='left', fontsize=10, color=colors[i], bbox=dict(facecolor='white', alpha=0.5))\n",
    "            \n",
    "            # Update previous end time and position\n",
    "            previous_end_time = segment_df.iloc[-1]['timestamp']\n",
    "            previous_end_position = (segment_df.iloc[-1]['position_x'], segment_df.iloc[-1]['position_y'])\n",
    "        \n",
    "        ax = plot_with_background(ax, 1)  # Assuming plot_with_background is defined elsewhere\n",
    "        ax.set_xlabel('Position X')\n",
    "        ax.set_ylabel('Position Y')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "plot_sample_tracks(test_linked, test_linked_duration, test_linked_distance, test_links, min_time=5, min_distance=10, min_links=2, grid_size=(16, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "plot_sample_tracks(test_linked, test_linked_duration, test_linked_distance, test_links, min_time=5, min_distance=10, min_links=2, grid_size=(8, 1), area='in_tb_pat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample lost tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=pd.errors.SettingWithCopyWarning)\n",
    "\n",
    "def filter_potential_matches(potential_matches: pd.DataFrame, last_point: pd.Series, time: int, distance: float) -> pd.DataFrame:\n",
    "\t# Filter potential matches based on time\n",
    "\tpotential_matches = potential_matches.copy()\n",
    "\tpotential_matches.loc[:, 'time_diff'] = potential_matches['time'] - last_point['time']\n",
    "\tpotential_matches = potential_matches[abs(potential_matches['time_diff']) <= time]\n",
    "\t\n",
    "\t# Filter potential matches based on distance\n",
    "\tpotential_matches.loc[:, 'distance'] = np.sqrt((potential_matches['position_x'] - last_point['position_x'])**2 + (potential_matches['position_y'] - last_point['position_y'])**2)\n",
    "\tpotential_matches = potential_matches[potential_matches['distance'] <= distance]\n",
    "\t\n",
    "\treturn potential_matches\n",
    "\n",
    "def plot_tracks(ax, df, track_id, color):\n",
    "\ttrack = df[df['track_id'] == track_id]\n",
    "\tax.plot(track['position_x'], track['position_y'], color=color, label=f'Track {track_id}')\n",
    "\t\n",
    "\t# Plot the first point as a large open circle\n",
    "\tax.plot(track['position_x'].iloc[0], track['position_y'].iloc[0], 'o', color=color, markersize=5, markerfacecolor='none')\n",
    "\t\n",
    "\t# Plot the last point as a large cross\n",
    "\tax.plot(track['position_x'].iloc[-1], track['position_y'].iloc[-1], 'x', color=color, markersize=5)\n",
    "\t\n",
    "\treturn ax\n",
    "\n",
    "def show_potential_matches(df, lost, max_time, max_distance, area = None):\n",
    "\t# Filter tracks based on lost argument\n",
    "\tif lost == 'start':\n",
    "\t\tlost_tracks = df.groupby('track_id').filter(lambda x: not x.iloc[0]['near_entry'])\n",
    "\t\tif area is not None:\n",
    "\t\t\tlost_tracks = lost_tracks.groupby('track_id').filter(lambda x: x.iloc[0][area])\n",
    "\telif lost == 'end':\n",
    "\t\tlost_tracks = df.groupby('track_id').filter(lambda x: not x.iloc[-1]['near_entry'])\n",
    "\t\tif area is not None:\n",
    "\t\t\tlost_tracks = lost_tracks.groupby('track_id').filter(lambda x: x.iloc[-1][area])\n",
    "\t\n",
    "\t# Sample one track_id\n",
    "\tsampled_track_id = lost_tracks['track_id'].sample(1).iloc[0]\n",
    "\tselected_track = df[df['track_id'] == sampled_track_id]\n",
    "\tlast_point = selected_track.iloc[-1]\n",
    "\tfirst_point = selected_track.iloc[0]\n",
    "\t\n",
    "\t# Plot the selected track_id\n",
    "\tfig, ax = plt.subplots(figsize=(8, 6))\n",
    "\tax = plot_with_background(ax, 1)\n",
    "\tax = plot_tracks(ax, df, sampled_track_id, 'black')\n",
    "\t\n",
    "\t# Find potential matches\n",
    "\teps = 3000  \n",
    "\tif lost == 'end':\n",
    "\t\tpotential_matches = df.drop_duplicates(subset='track_id', keep='first')\n",
    "\t\tpotential_matches = potential_matches[potential_matches['near_entry'] == False]\n",
    "\t\tpotential_matches = potential_matches[potential_matches['time'] > (last_point['time'] - eps)]\n",
    "\t\tpotential_matches = filter_potential_matches(potential_matches, last_point, max_time, max_distance)\n",
    "\telse:\n",
    "\t\tpotential_matches = df.drop_duplicates(subset='track_id', keep='last')\n",
    "\t\tpotential_matches = potential_matches[potential_matches['near_entry'] == False]\n",
    "\t\tpotential_matches = potential_matches[potential_matches['time'] < (first_point['time'] + eps)]\n",
    "\t\tpotential_matches = filter_potential_matches(potential_matches, first_point, max_time, max_distance)\n",
    "\tpotential_matches_tracks = df[df['track_id'].isin(potential_matches['track_id'])]\n",
    "\tpotantial_matches_duration = compute_track_duration(potential_matches_tracks)\n",
    "\tpotential_matches_distance = compute_track_distance(potential_matches_tracks)\n",
    "\tpotential_matches = pd.merge(potential_matches, potantial_matches_duration, on='track_id')\n",
    "\tpotential_matches = pd.merge(potential_matches, potential_matches_distance, on='track_id')\n",
    "\n",
    "\tif potential_matches.empty:\n",
    "\t\tplt.show()\n",
    "\t\treturn\n",
    "\t\n",
    "\t# Plot potential matches in different colors\n",
    "\tcolors = plt.get_cmap('tab10', len(potential_matches))\n",
    "\tcolor_map = {}\n",
    "\tfor i, (track_id, match) in enumerate(potential_matches.groupby('track_id')):\n",
    "\t\tcolor_map[track_id] = colors(i)\n",
    "\t\tax = plot_tracks(ax, df, track_id, colors(i))\n",
    "\t\n",
    "\t# Create a table listing time difference and distance\n",
    "\ttable_data = []\n",
    "\tfor track_id, match in potential_matches.groupby('track_id'):\n",
    "\t\ttime_diff = round(match['time_diff'].iloc[0] / 1000)\n",
    "\t\tdistance = round(match['distance'].iloc[0], 1)\n",
    "\t\tmatch_duration = round(match['duration'].iloc[0] * 60)\n",
    "\t\tmatch_distance = round(match['total_distance'].iloc[0], 1)\n",
    "\t\ttable_data.append([track_id, time_diff, distance, match_duration, match_distance])\n",
    "\t\n",
    "\t# Adjust layout to make space for the table\n",
    "\tplt.subplots_adjust(bottom=0.3)\n",
    "\t\n",
    "\t# Plot the table below the plot\n",
    "\ttable = ax.table(cellText=table_data, colLabels=['Track ID', 'Time Difference (s)', 'Distance (m)', 'Duration (s)', 'Total distance (m)'], loc='bottom', bbox=[0, -0.3, 1, 0.2])\n",
    "\ttable.auto_set_font_size(False)\n",
    "\ttable.set_fontsize(8)\n",
    "\t\n",
    "\t# Set row text colors to match plot colors\n",
    "\tfor i, key in enumerate(table.get_celld().keys()):\n",
    "\t\tcell = table.get_celld()[key]\n",
    "\t\tif key[0] > 0:  # Skip header row\n",
    "\t\t\ttrack_id = table_data[key[0] - 1][0]\n",
    "\t\t\tcell.set_text_props(color=color_map[track_id])\n",
    "\t\n",
    "\tplt.show()\n",
    "\n",
    "md = 1.5\n",
    "mt = 10*60*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_potential_matches(test_linked, lost='start', max_time=mt, max_distance=md)\n",
    "show_potential_matches(test_linked, lost='start', max_time=mt, max_distance=md)\n",
    "show_potential_matches(test_linked, lost='start', max_time=mt, max_distance=md)\n",
    "show_potential_matches(test_linked, lost='start', max_time=mt, max_distance=md)\n",
    "show_potential_matches(test_linked, lost='start', max_time=mt, max_distance=md)\n",
    "show_potential_matches(test_linked, lost='end', max_time=mt, max_distance=md)\n",
    "show_potential_matches(test_linked, lost='end', max_time=mt, max_distance=md)\n",
    "show_potential_matches(test_linked, lost='end', max_time=mt, max_distance=md)\n",
    "show_potential_matches(test_linked, lost='end', max_time=mt, max_distance=md)\n",
    "show_potential_matches(test_linked, lost='end', max_time=mt, max_distance=md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_potential_matches(test_linked, lost='start', max_time=mt, max_distance=md, area=\"in_tb_pat\")\n",
    "show_potential_matches(test_linked, lost='start', max_time=mt, max_distance=md, area=\"in_tb_pat\")\n",
    "show_potential_matches(test_linked, lost='start', max_time=mt, max_distance=md, area=\"in_vitals_pat\")\n",
    "show_potential_matches(test_linked, lost='start', max_time=mt, max_distance=md, area=\"in_vitals_pat\")\n",
    "show_potential_matches(test_linked, lost='end', max_time=mt, max_distance=md, area=\"in_tb_pat\")\n",
    "show_potential_matches(test_linked, lost='end', max_time=mt, max_distance=md, area=\"in_tb_pat\")\n",
    "show_potential_matches(test_linked, lost='end', max_time=mt, max_distance=md, area=\"in_vitals_pat\")\n",
    "show_potential_matches(test_linked, lost='end', max_time=mt, max_distance=md, area=\"in_vitals_pat\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
